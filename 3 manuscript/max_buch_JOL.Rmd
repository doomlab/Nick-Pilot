---
title             : "Investigating the Interaction of Direct and Indirect Relation on Memory Judgments and Retrieval"
shorttitle        : "Judgments and Recall"

author: 
  - name          : "Nicholas P. Maxwell"
    affiliation   : "1"
  - name          : "Erin M. Buchanan"
    affiliation   : "2"
    corresponding : yes    # Define only one corresponding author
    address       : "326 Market St., Harrisburg, PA, 17101"
    email         : "ebuchanan@harrisburgu.edu"

affiliation:
  - id            : "1"
    institution   : "University of Southern Mississippi"
  - id            : "2"
    institution   : "Harrisburg University of Science and Technology"

author_note: >
  Nicholas P. Maxwell is a Ph.D. candidate at the University of Southern Mississippi. Erin M. Buchanan is a Professor of Cognitive Analytics at Harrisburg University of Science and Technology. We thank two anonymous reviewers for their suggestions in updating and strengthening our paper. 
  
abstract: >
  This study examined the interactive relationship between two measures of association (direct and indirect associations) when predicting relatedness judgments and cued-recall performance. Participants were recruited from Amazon's Mechanical Turk and were given word pairs of varying relatedness to judge for their semantic, thematic, and associative strength. After completing a distractor task, participants then completed a cued recall task. First, we sought to expand previous work on judgments of associative memory (JAM) to include semantic and thematic based judgments (judgments of relatedness, JOR), while also replicating bias and sensitivity findings. Next, we tested for an interaction between direct and indirect association when predicting participant judgments while also expanding upon previous work by examining that interaction when predicting recall. The interaction between direct and indirect association was significant for both judgments and recall. For low indirect association, direct association was the primary predictor of both judgment strength and recall proportions. However, this trend reversed for high indirect association, as higher levels of indirect relation decreased the effectiveness of direct relation as a predictor. Overall, our findings indicate the degree to which the processing of similarity information impacts cognitive processes such as retrieval and item judgments, while also parsing apart the underlying, interactive relationship that exists between the norms used to represent concept information.

keywords          : "judgments, memory, association, semantics, thematics"

bibliography      : ["nick_ref.bib"]

figsintext        : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes

lang              : "english"
class             : "man"
output            : papaja::apa6_pdf
replace_ampersands: yes
csl               : apa6.csl
---

```{r libraries, include = FALSE}
knitr::opts_chunk$set(cache = TRUE)

p.value = function(x){
  if (x < .001) { return("< .001")}
  else { return(apa(x, 3, F))}
}

pasteit = function(M, SD){
  return(paste(printnum(M, gt1 = F), " (",
        printnum(SD, gt1 = F), ")", sep = ""))
}

library(papaja)
library(cowplot)
library(MOTE)
library(ggplot2)
library(ez)
library(lsa)
library(kableExtra)
library(nlme)
library(knitr)
library(lme4)

cleanup = theme(panel.grid.major = element_blank(), 
                panel.grid.minor = element_blank(), 
                panel.background = element_blank(), 
                axis.line.x = element_line(color = "black"),
                axis.line.y = element_line(color = "black"),
                legend.key = element_rect(fill = "white"),
                text = element_text(size = 15))

cleanup2 = theme(panel.grid.major = element_blank(), 
                panel.grid.minor = element_blank(), 
                panel.background = element_blank(), 
                axis.line.x = element_line(color = "black"),
                axis.line.y = element_line(color = "black"),
                legend.key = element_rect(fill = "white"),
                text = element_text(size = 12), 
                plot.title = element_text(hjust = 0.5)) 
```

The study of cognition has a rich history of exploring the way in which associations affect human memory. One key finding is that associations between items influence cognitive processing and play a critical role in how well an individual retains learned information. Throughout the mid-20th century, researchers investigated this notion, particularly through the use of paired-associate learning (PAL) tasks. In this paradigm, participants are presented with a pair of items and are asked to make connections between them so that the presentation of one item (the cue) will in turn trigger the recall of the other (the target). Early studies of this nature focused primarily on the effects of meaning and imagery on recall performance. For example, @Smythe1968 found that noun imagery played a crucial role in PAL performance; subjects were much more likely to remember word-pairs that were low in meaning similarity if imagery between the two was high. Subsequent studies in this area focused on the effects of mediating variables on PAL tasks as well as the effects of imagery and meaningfulness on associative learning [@Richardson1998], with modern studies shifting their focus towards a broad range of applied topics such as how PAL is affected by aging [@Hertzog2002], its impacts on second language acquisition [@Chow2014], and even within the context of evolutionary psychology [@Schwartz2013]. The present study contributes to this area by examining PAL within the context of judgments of relatedness (JORs) for three types of concept information. Furthermore, we investigate how two types of item associations (direct and indirect) influence the accuracy of these judgments.

Early PAL studies routinely relied on stimuli generated from word lists that focused extensively on measures of word frequency, concreteness, meaningfulness, and imagery [@Paivio1969]. However, the word pairs in these lists were typically created due to their apparent relatedness or frequency of occurrence in text. While lab self-generation appears face valid, one finds that this method of selection lacks a decisive method of defining the underlying relationships between the pairs [@Buchanan2010], as these variables only capture psycholinguistic measurements of an individual concept (i.e., how concrete is *cat* and word occurrence). PAL is, by definition, used on word pairs, which requires examining concept relations in a reliable manner. As a result, free association norms have become a common means of indexing associative strength between word pairs [@Nelson2000]. 

## Measuring Association

Within cognitive psychology, word associations have been conceptualized differently across various lines of research (i.e., direct word associations, mediated associates, etc.; see @DeDeyne2013 for a review). For the present study, we focus exclusively on two types of associations: Direct associations and indirect associations. Direct word associations are traditionally viewed as the probability that the first word in the pair will cue the second as a response [@Nelson2000]. Within this framework, word associations are thought to arise in several different ways. These associations may develop through their co-occurrence together in either written or spoken language. The terms *peanut* and *butter* have become associated over time through their joint use to depict a particular type of food, though separately, the two concepts share very little overlap in terms of meaning. However, this lack of shared meaning is not the case for all associative pairs. For example, word associations capture the knowledge that fish live in water (e.g., *fish* â€“ *swim*) and that *dogs* and *cats* share many similar features. To generate norms measuring direct associations, participants engage in a free association task, in which they are presented with a cue word and are asked to list the first related target word that comes to mind. The probability of producing a given response to a particular cue word (i.e., the pair's normed forward strength, FSG) can then be determined by dividing the number of participants who produced the response in question by the total number of responses generated for that word [@Nelson2000]. Thus, the free association process can be thought of as generating an index that contains the relative accessibility of related words in memory [@Nelson2004]. 

Using this technique, researchers have developed databases of associative word norms that can be used to generate stimuli, generally with a high degree of reliability [e.g., The University of South Florida Free Association Norms; @Nelson2004]. However, this reliability becomes questionable for weak associates. Because the traditional free association task focuses solely on the first word that is provided in response to the cue, target items that are more weakly associated may become underrepresented in the dataset, as the inclination to respond with stronger associates may disrupt access to weaker associates (i.e., the availability heuristic). Recently, The Small World of Words project [SWOW, @DeDeyne2013; @DeDeyne2018] has sought to correct for this sampling issue by employing a multiple response free association task. In this modified free association task, subjects are asked to generate three target items in response to the cue. The updated SWOW association norms provide several advantages when compared to other collections of free association norms. First, this norm set is the largest to date, consisting of approximately 12,000 cue items (for comparison, the USF norms consist of 5,400 cue items). Because of its large size, the SWOW norms provide a better approximation of natural language. Second, the use of a multiple response technique allows for greater reliability of weak associates, resulting in more weak associations being captured by the network, as weak associates are rarely given as the first response and thus may be underrepresented when only one response is elicited [@DeDeyne2013]. 

## Measuring Relatedness

Whereas direct associations focus on the relationships between individual words, indirect associations instead focus on how a concept fits into the overall structure of the semantic network [@DeDeyne2013; @Deese1965]. Because indirect associations capture information derived from the overall structure of the semantic network, these norms can also be used to represent semantic properties of item pairs and can be used to approximate links between concepts within semantic memory networks. This includes mediated associates (i.e., *lion* - *stripes* is mediated through *tiger*; see @Huff2011 for a review of mediated associates) and is one of the underlying factors behind distributional models of semantic memory [e.g., Latent Semantic Analysis, @Landauer1997; Hyperspace Analogue to Language Model, @Lund1996]. These models posit that semantic representations are created through the co-occurrences of words together within a body of text and suggest that words with similar meanings will appear together in similar contexts [@Riordan2011]. 

Measuring this semantic overlap between concepts in a memory network can be performed in several ways. Feature production tasks [@McRae2005; @Vinson2008; @Buchanan2013; @Buchanan2019] provide one means of generating semantic word norms. In such tasks, participants are shown the name of a concept and are asked to list what they believe the concept's most important features to be [@McRae2005]. Several statistical measures have been developed which measure the degree of feature overlap between concepts. Similarity between any two concepts can be measured by representing them as vectors and calculating the cosine value (COS) between them [@Maki2004], with the derived COS values ranging from 0 (completely unrelated) to 1 (perfectly related). For example, the pair *hornet* - *wasp* has a COS of .88, indicating a high degree of overlap between the two concepts. 

Indirect associations computed from a large dataset can also be used as a measure of semantic overlap, and indeed may provide a better measure of semantic relatedness relative to feature production norms [@DeDeyne2013]. @DeDeyne2013 constructed a semantic network based on the distributions of associations (e.g., indirect associates) by converting free association data taken from the SWOW project into a weighted semantic network. Computing the cosine overlap between the distribution of free association responses on any two concepts within this network provides a useful measure of meaning.

Discussion of these measures of associative and semantic overlap leads to the question of whether each type of measure is truly assessing some unique concept or if they simply tap into various elements of our overall linguistic knowledge. Previous clustering and factor analyses by @Maki2008 indicates that there are potentially three separate latent structures represented by these various measures of similarity: Associative, semantic, and thematic types of relatedness. However, another interpretation of their results is that the data collection of the measurement matters, as variables that are based on participant responses to cued stimuli grouped together, while text-corpora and WordNET based similarity measures separated into distinct factors. By using the participant responses from SWOW to measure indirect association, we draw from a larger, newer set of data and resolve a potential confound of conflating measurement techniques. 

## Application to Judgment Studies

Traditional judgment of learning tasks (JOL) can be viewed as an application of the PAL paradigm; participants are given pairs of items and are asked to judge how accurately they would be able to correctly respond with the target with the cue on a recall task. Judgments are typically made out of 100, with a participant response of 100 indicating full confidence in recall ability. In their 2005 study, Koriat and Bjork examined overconfidence in JOLs by manipulating associative relations (forward strength from @Nelson2004) between word-pairs and found that subjects were more likely to overestimate recall for pairs with little or no associative relatedness. For example, the pair *bird* - *feather* in the SWOW norms appears to have a low forward strength (.031). However, the semantic relatedness between the two is higher (.063) when indexed using SWOW's indirect association norms. Therefore, it is important to investigate what may lead to the perceived relatedness between the item pairs and result in inflated judgments.

The JOL task can be manipulated to investigate perceptions of word pair relation by having participants judge how related they believe the cue and target items to be [@Maki2007a; @Maki2007]. The judged values generated from this task can then be directly compared to the normed databases to create a similar accuracy function or correlation as is created in JOL studies. When presented with the item pair, participants are asked to estimate the number of people out of 100 who would provide the target word when shown only the cue [@Maki2007], which mimics how association word norms are created through free association tasks. @Maki2007a investigated such judgments within the context of associative memory by having participants rate how much associative overlap was shared between normed item pairs and found that responses were greatly overestimated relative to the actual normed overlap strength for pairs that were weak associates, while underestimated for strong associates, thus replicating the @Koriat2005 findings for relatedness judgments based upon associative memory, rather than judgments based on learning.

The judgment of associative memory (JAM) function provides one means of visualizing the influence that various cognitive biases have on associative memory judgments. By plotting the judged values against the word pair's normed associative strength, a fit line can be calculated which displays the calibration of JAM ratings relative to normed associative strength. When plotted, these judgments characteristically have a high intercept (indicative of an overestimation bias for weak and moderately associated word pairs) along with a shallow slope (low sensitivity to changes in normed pair strength). Figure \@ref(fig:makislope) illustrates this function. Overall, the JAM function has been shown to be highly reliable and generalizes well across multiple variations of the study, with item characteristics such as word frequency, cue set size (QSS), and semantic similarity all having a minimal influence on the function [i.e., similar intercepts and slopes were found for manipulations of these variables, including semantic similarity of the word pairs; @Maki2007]. Furthermore, an applied meta-analysis of more than ten studies on JAM indicated that bias and sensitivity are nearly unchangeable, often hovering around 40-60 points for the intercept and .20-.30 for the slope [@Valentine2013]. Additionally, the @Valentine2013 study extended this research to include judgments of semantic memory with the same results. Finally, @DeDeyne2013a found that JAM ratings for weak and moderate associates are best predicted by continuous response association norms relative to traditional free association norms.

We use the term bias to indicate the overestimation of ratings for weak to moderately related pairs, as described in @Maki2007. However, the original @Maki2007 study used the @Nelson2004 norms as a metric to measure against, and measurement bias likely also exists. As mentioned earlier, these weaker associates may be underrepresented in the data using the one response free association task; thus, lowering their estimates and making participant estimates appear upwardly biased. By using the larger SWOW data, this study can explore whether the overestimation bias persists with less measurement bias by using the continuous response association set. 

```{r makislope, echo=FALSE, fig.cap = "JAM slope findings from Maki (2007a). JAM is characterized by a high intercept (between 40 and 60) and a shallow slope (between 0.20 and 0.40). The solid line shows expected results if judgment ratings are perfectly calibrated with association norms.", fig.height=6, fig.width=6}

####JAM plot####
fakedata = data.frame(FSG = 0:100,
                      JAM = 0:100)

plot1 = ggplot(fakedata, aes(FSG, JAM)) + 
  xlab("Forward Strength") +
  ylab("Participant Judgments") +
  geom_abline(aes(intercept = 0, slope = 1, linetype = "Expected")) +
  geom_abline(aes(intercept = 50, slope = .30, linetype = "JAM")) + 
  scale_size_continuous(guide = FALSE) +
  scale_linetype_manual(values = c("solid", "dashed"),
                        breaks = c("Expected", "JAM"),
                        name = "Function") +
  coord_cartesian(xlim = c(0,100), ylim = c(0,100)) +
  geom_vline(xintercept = -5) +
  geom_hline(yintercept = -5) +
  cleanup 
  
plot1 + theme(legend.position = c(.75, .25))

```

The discrepancy between direct association strength and JAM ratings is noteworthy because on the surface, the two tasks should each be tapping into the same concept of associative overlap. One explanation for this provided by @Maki2007a is that judgment tasks are more easily influenced by outside factors such as the availability heuristic. Thus, it may be that the mere act of viewing the cue-target pair together at the time of judgment interferes with individuals' ability to consider other target words that are related to the cue, thereby inflating (or reducing) the perceived relatedness between the items [@Maki2007a]. Indeed, work by [@Nelson1991] has shown this to be the case when eliciting judgments of learning, as JOLs made after a delay tend to be more accurate relative to those made immediately in the presence of the studied information. Further, the influence of indirect relations on judgments has not been investigated within the context of multiple judgment types (but see @DeDeyne2013 for a review of both SWOW association types within the context of semantic similarity judgments).

The present study expanded upon previous JAM studies by examining recall rates and judgment strengths for three types of judgments of relatedness (associative, semantic, and thematic; JORs) with the goal of exploring the underlying memory network that is used for each of these cognitive processes as described above. To date, no study has investigated how the three types of concept information affect these judgment and recall processes within the context of one unified study. Thus, the ensuing JOR task is a direct extension of Maki's (2007a) JAM task. As such, we tested four hypotheses, which were based upon previous research on JAM and semantic memory models.

First, we sought to expand upon previous @Maki2007a, @Maki2007, @Buchanan2010, and @Valentine2013 research by using an extended JAM task that included three types of judgments within one experiment (i.e., associative, semantic, and thematic judgments), while replicating JAM bias and sensitivity findings (Hypothesis 1). Because the judgment task we employ is an extended JAM task that also includes semantic and thematic judgments, we subsequently refer to all judgment tasks as a judgment of relatedness task (JOR), regardless of which type of judgment is being elicited. We used the SWOW norms, calculating direct and indirect relations to best capture the continuum of similarity between concepts. These values were used to predict each type of JOR, and we calculated average slope and intercept values for each participant. We expected to find slope and intercept values that were significantly different from zero. Though the three types of word relations are distinct from one another, we should expect to find slopes and intercepts for semantic and thematic JORs to be within the range of previous JAM findings if these memory systems are interconnected. We also examined the frequency of each predictor being the strongest variable to predict an individual judgment condition. Thus, we are interested in exploring whether judgment findings replicate across each judgment type while using the new measurement variables available through SWOW (rather than each individually, as tested in previous JOL and JAM publications), which expands our knowledge on how the judgment process taps into the underlying memory network.

Next, we explored the predictions from semantic network models that the relation between associations and semantics would be interconnected by nature (i.e., both types of knowledge closely linked in memory). Therefore, we expected to find an interaction between direct and indirect association norms when predicting JORs. We used multilevel modeling to examine the interaction of these norms in relation to participant judgments (Hypothesis 2). 

We then extended these analyses to include recall as the dependent variable of interest (Hypothesis 3). We tested for the interaction of database norms in predicting recall by using a multilevel logistic regression, while controlling for judgment conditions and rating. We expected to find that database norms would show differences in recall based on the levels of other variables (the interaction would be significant), and that ratings would also positively predict recall (i.e., words that participants thought were more related would be remembered better). Because judgment making and recall are different cognitive processes, we used this hypothesis to examine how the interactive structure of memory networks may differ based on task.

Finally, we examined if the judgment slopes from Hypothesis 1 would be predictive of recall (Hypothesis 4). Whereas the recall model used to test our third hypothesis examined the direct relationship of word relatedness on recall, the goal of this analysis was to explore whether participant sensitivity to word relatedness could also be used to predict recall. For this analysis, we used a multilevel logistic regression to control for multiple judgment slope conditions. This hypothesis combined both cognitive processes into one analysis so as to explore how judgment ability (i.e., slopes) would impact the memory process.

# Method

## Participants

```{r data_import, include = F}

pilot = read.csv("data/Melted Data pilot.csv", stringsAsFactors = F)
thesis = read.csv("data/Melted Data Thesis.csv", stringsAsFactors = F)

thesis$Partno = thesis$Partno + 1000
pilot$where = "pilot"
thesis$where = "thesis"

colnames(pilot)[2] = "Judgment"

master = rbind(pilot, thesis)
```

```{r power, eval = F, include = F}
####power test####
#library(nlmeU)
#library(simr)
#Pwr(overallh2)

#powerest = rep(NA, 99)
#samplesizetest = seq(1*63, 100*63, 62) ##set up sample sizes to test
#sim = 1
#for (i in samplesizetest){

#smalldata = sample(noout, i)

#testh2 = lme(Judged.Value2 ~ Judgment +
#               ZCOS * ZLSA * ZFSG,
#             data = smalldata,
#             method = "ML",
#             na.action = "na.omit",
#             random = ~1|Partno)
#powerest[sim] = Pwr(testh2)[9,5]
#sim = sim + 1
#}

#powerest
#{plot(powerest)
#abline(h = .80)}
```

A power analysis was conducted using the *simR* package in *R* [@Green2016]. This package uses simulations to generate power estimates for mixed linear models created from the *lme4* package in *R* [@Bates2015]. The results of this analyses suggested a minimum of 35 participants would be required to detect an effect. However, because power often tends to be underestimated, we extended participant recruitment as funding permitted. The data in this experiment were collected in two waves of recruiting from Amazon's Mechanical Turk, which is a website that allows individuals to host projects and connects them with a large pool of respondents who complete them for small amounts of money [@Buhrmester2011]. In the first wave, a total of `r length(unique(master$Partno[master$where == "pilot"]))` participants were recruited, and in the second wave, `r length(unique(master$Partno[master$where == "thesis"]))` participants were recruited. Participant responses were screened for a basic understanding of the study's instructions. Responses were rejected for participants who entered related words when numerical judgment responses were required and for participants who responded to the cue words during the recall phase with sentences or phrases instead of individual words. Those that completed the study correctly were compensated \$1.00 for their participation in wave one, and \$2.00 for their participation in wave two. The second wave of participants was sponsored by graduate thesis funding provided by the Missouri State University Graduate College. 

## Materials

The stimuli used were `r length(unique(master$Word.Pair))` word pairs of varying relatedness, which were derived from the @Buchanan2013 word norm database and website. These pairs were evenly split into sixty-three pairs for wave one and wave two of the study. Pairs were originally selected by using forward strength [FSG; @Nelson2004], semantic feature overlap cosine values (COS) from @Buchanan2013, and Latent Semantic Analysis cosine values [@Landauer1998; @Landauer1997] based on previous research on how word pair psycholinguistic variables overlap [@Maki2008]. The selected stimuli included a range of values for each variable. Table \@ref(tab:stim-table) displays descriptive statistics for the stimuli pairs. A complete list of stimuli can be found at http://osf.io/y8h7v. 

The stimuli were arranged into three blocks for each judgment condition described below wherein each block contained 21 word pairs. Due to limitations of the available stimuli, blocks were structured so that each one contained seven word pairs of low (0-.33), medium (.34-.66), and high (.67-1.00) COS relatedness. Pairs with low, medium, and high FSG and LSA were then selected, when available. Given the measurement questions raised in the introduction, the direct association from the SWOW norms will be used as the measure of first order association. Based on @DeDeyne2013a's work on continuous association, the response set from all three responses were used. The direct association provided in these norms is calculated as the number of participants who provided the target to the cue divided by the number of possible answers (i.e., participants $\times$ responses). This calculation, therefore, has an upper limit of approximately ~33%, even if every participant listed a target word to a cue. The JOR task assumes the range of direct association is 0 to 100 (or 0-1 proportion), and the SWOW direct association (DA) was normalized using: 

$$\frac{DA - Min(DA)} {Max(DA) - Min(DA)}$$

Indirect association (IA) was calculated by comparing the distribution of responses for each concept. Therefore, if the concepts were *bird* and *feather*, the two association sets were combined and the cosine between the response frequencies was calculated. Cosine indicates a measure of overlap in the response distributions, where 0 indicates no overlapping responses, while 1 indicates perfectly overlapping response frequencies [see @Buchanan2019 for more on cosine feature overlap]. DA and IA averages are provided in Table \@ref(tab:stim-table). The study was built online using Qualtrics, and three surveys were created to counter-balance the order in which judgment conditions appeared. Each word pair appeared counter-balanced across each judgment condition, and stimuli were randomized within each block.

```{r direct_association, include = F}

swow = read.csv("data/strength.SWOW-EN.R123.csv", stringsAsFactors = F)

swow$pair = paste(swow$cue, swow$response, sep = "_")
swow$pair = tolower(swow$pair)
swow$cue = tolower(swow$cue)
swow$response = tolower(swow$response)
swow = swow[-c(1001283) , ] #remove the dup

master$pair = gsub("...", "_", master$Word.Pair, fixed = T)
master$pair = tolower(master$pair)

master2 = merge(master, swow, by = "pair", all.x = T)
nrow(master2)
##red yellow is duplicating - removing the duplicate line from swow

#normalize SWOW as the score is not number of participants who said X / number of participants, but instead is number of participants who said X / number of answers
#normalized = (x-min(x)) / (max(x) - min(x))

master2$swow_fsg = (master2$R123.Strength - min(master2$R123.Strength, na.rm = T)) / (max(master2$R123.Strength, na.rm = T) - min(master2$R123.Strength, na.rm = T))

master2$swow_fsg[is.na(master2$swow_fsg)] = 0
```

```{r indirect_association, include = F}

paired = unique(master2$pair)
paired = as.data.frame(paired)
paired$paired = as.character(paired$paired)
paired$cosine = NA

for (i in 1:length(paired$paired)){ #loop over each word
  
  words = strsplit(paired$paired[i], "_")
  temp1 = swow[tolower(swow$cue) == words[[1]][1], ]
  temp2 = swow[tolower(swow$cue) == words[[1]][2], ]
  
  temp_merge = merge(temp1, temp2, by = "response", all = T)
  temp_merge$R123.Strength.x[is.na(temp_merge$R123.Strength.x)] = 0
  temp_merge$R123.Strength.y[is.na(temp_merge$R123.Strength.y)] = 0
  
  paired$cosine[i] = lsa::cosine(temp_merge$R123.Strength.x, temp_merge$R123.Strength.y)

}

#merge with  our data
colnames(paired)[1] = "pair"
master3 = merge(paired, master2, by = "pair")
```

```{r stim-table, echo=FALSE, results='asis'}
##create blank table
tableprint = matrix(NA, nrow = 5, ncol = 4)
colnames(tableprint) = c("Variable", "Low", "Average", "High")

##create a unique dataset
stimuli = master3[!duplicated(master3$pair), ]

##add cosine labels
stimuli$range = NA
stimuli$range[stimuli$COS < .33] = "low"
stimuli$range[stimuli$COS >= .33 & stimuli$COS < .66] = "med"
stimuli$range[stimuli$COS >= .66] = "high"
stimuli$range = factor(stimuli$range,
                       levels = c("low", "med", "high"))

##calculate means and sds
COSM = tapply(stimuli$COS, stimuli$range, mean)
COSSD = tapply(stimuli$COS, stimuli$range, sd)
tableprint[ 1, ] = c("Semantic Feature Overlap COS", 
                     pasteit(COSM[1], COSSD[1]),
                     pasteit(COSM[2], COSSD[2]),
                     pasteit(COSM[3], COSSD[3]))

FSGM = tapply(stimuli$FSG, stimuli$range, mean)
FSGSD = tapply(stimuli$FSG, stimuli$range, sd)
tableprint[ 2, ] = c("Forward Strength FSG", 
                     pasteit(FSGM[1], FSGSD[1]),
                     pasteit(FSGM[2], FSGSD[2]),
                     pasteit(FSGM[3], FSGSD[3]))

LSAM = tapply(stimuli$LSA, stimuli$range, mean)
LSASD = tapply(stimuli$LSA, stimuli$range, sd)
tableprint[ 3, ] = c("Latent Semantic Analysis LSA", 
                     pasteit(LSAM[1], LSASD[1]),
                     pasteit(LSAM[2], LSASD[2]),
                     pasteit(LSAM[3], LSASD[3]))                     
                     
DAM = tapply(stimuli$swow_fsg, stimuli$range, mean)
DASD = tapply(stimuli$swow_fsg, stimuli$range, sd)
tableprint[ 4, ] = c("Direct Association", 
                     pasteit(DAM[1], DASD[1]),
                     pasteit(DAM[2], DASD[2]),
                     pasteit(DAM[3], DASD[3]))                     
                     
IAM = tapply(stimuli$cosine, stimuli$range, mean)
IASD = tapply(stimuli$cosine, stimuli$range, sd)
tableprint[ 5, ] = c("Indirect Association", 
                     pasteit(IAM[1], IASD[1]),
                     pasteit(IAM[2], IASD[2]),
                     pasteit(IAM[3], IASD[3]))  

kable(tableprint, "latex", booktabs = T, row.names = F, 
      caption = "Summary Statistics for Stimuli") %>%  
  add_header_above(c(" " = 1, "Semantic Feature Overlap COS" = 3)) %>% 
  add_footnote("$Note$. Standard deviation values are in parentheses.", notation="none", escape = F)
```

## Procedure

The present study was divided into three phases. In the first phase, JORs were elicited by presenting participants with word pairs and asking them to make judgments of how related they believed the words in each pair to be. This judgment phase consisted of three blocks of 21 word pairs which corresponded to one of three types of described word pair relationships: Associative, semantic, or thematic. Each block was preceded by a set of instructions explaining one of the three types of relationships, and participants were provided with examples which illustrated the type of relationship to be judged. Participants were then presented with the word pairs to be judged. The associative block began by explaining associative memory and the role of free association tasks. Participants were provided with examples of both strong and weak associates. For example, *lost* and *found* were presented as an example of a strongly associated pair, while *article* was paired with *newspaper*, *the*, and *clothing* to illustrate that words can have many weak associates. The semantic judgment block provided participants with a brief overview of how words are related by meaning and showed examples of concepts with both high and low feature overlap. *Tortoise* and *turtle* were provided as an example of two concepts with significant overlap. Other examples were then provided to illustrate concepts with little or no overlap. For the thematic judgments, participants were provided with an explanation of thematic relatedness. *Tree* is explained to be related to *leaf*, *fruit*, and *branch*, but not *computer*. For each judgment condition, participants were then given three concepts (*lost*, *old*, *article*) and were asked to come up with words that they felt were related to that type of relation. 

After viewing the examples at the start of the block, participants completed the JOR task. Each block contained a set of instructions which were contingent upon the type of JOR being elicited. For example, instructions in the associative block asked participants to estimate how many individuals out of 100 they expect would respond to the cue word with a given target, instructions for semantic JORs asked participants to indicate the percent of features shared between two concepts, and instructions for the thematic JOR task asked participants to base ratings on how likely to words would be used together in the same story. The complete experiment can be found at http://osf.io/y8h7v, which contains the exact instructions given to participants for each block and displays the structure of the study. All instructions were modeled after @Buchanan2010 and @Valentine2013.

In accordance with previous work on JOLs and JAM, participants made JOR ratings using a scale of zero to one hundred, with zero indicating no relationship, and one hundred indicating a perfect relationship. Participants typed their responses into the survey. Once finished, participants then completed the remaining judgment blocks in the same manner. Each subsequent judgment block changed the type of JOR being made. Three versions of the study were created, which counter-balanced the order in which the judgment blocks appeared, and participants were randomly assigned to a survey version. This resulted in each word pair receiving a relatedness judgment on each of the three types relationships. 

After completing the judgment phase, participants were then presented with a short distractor task to account for recency effects. In this section, participants were presented with a randomized list of the fifty U.S. states and were asked to arrange them in alphabetical order. This task was timed to last two minutes. Once time had elapsed, participants automatically progressed to the final phase, which consisted of a cued-recall task. Participants were presented with each of the sixty-three cue words from the judgment phase and were asked to complete each word pair by responding with the correct target word. Participants were informed that they would not be penalized for guessing. The cued-recall task included all stimuli in a random order.

# Results

```{r data-set-creation, include=FALSE}
##check out our 2 datasets folder to see how these datasets were made
##we moved the data into long format, and combined them all together by judgment and recall
##then we combined these data with psycholinguistic norms (in excel, if I remember correctly)
##then we merged them together in this file 

#scaling judgments
master3$Judged.Value = master3$Judged.Value / 100

#clean up judgment type
master3$Judgment = gsub("semantic", "Semantic", master3$Judgment)
master3$Judgment = gsub("associative", "Associative", master3$Judgment)
master3$Judgment = gsub("thematic", "Thematic", master3$Judgment)
```

```{r data-screening, include=FALSE}
##accuracy
summary(master3)
##fixing judged value
badjudge = sum(!is.na(master3$Judged.Value[ master3$Judged.Value > 1 ]))
master3$Judged.Value[ master3$Judged.Value > 1 ] = NA
#summary(master3$Judged.Value)

##missing data will be excluded below
missingness = table("judge" = is.na(master3$Judged.Value), "recall" = is.na(master3$Recall))

##outliers based on recall and judgment
mahal = mahalanobis(master[ , c(6,7)],
                    colMeans(master[ , c(6,7)], na.rm = TRUE),
                    cov(master[ , c(6,7)], use = "pairwise.complete.obs"))
cutoff = qchisq(1-.001, ncol(master[ , c(6,7)]))
cutoff;ncol(master[ , c(6,7)])
summary(mahal < cutoff)
noout = subset(master3, mahal < cutoff)

##additivity
cor(noout[ , c(2,6,7,55)], use = "pairwise.complete.obs")
cor(noout[ noout$Judgment == "Semantic", c(2,6,7,55)], use = "pairwise.complete.obs")
cor(noout[ noout$Judgment == "Associative", c(2,6,7,55)], use = "pairwise.complete.obs")
cor(noout[ noout$Judgment == "Thematic", c(2,6,7,55)], use = "pairwise.complete.obs")

##descriptive stats
meanJno = tapply(noout$Judged.Value, noout$Judgment, mean, na.rm = T) * 100
meanRno = tapply(noout$Recall, noout$Judgment, mean, na.rm = T) * 100
sdJno = tapply(noout$Judged.Value, noout$Judgment, sd, na.rm = T) * 100 
sdRno = tapply(noout$Recall, noout$Judgment, sd, na.rm = T) * 100
```

## Data Processing and Descriptive Statistics

First, the results from the recall phase of the study were coded as zero for incorrect responses, one for correct responses, and NA for participants who did not complete the recall section (all or nearly all responses were blank). All word responses to judgment items were deleted and set to missing data^[The final dataset was created by splitting the initial data file into six sections (one for each of the three experimental blocks and their corresponding recall scores). Each section was individually melted using the *reshape* package in *R* [@Wickham2007] and was written as a csv file. The six output files were then combined to form the final dataset. Code is available on our OSF page embedded inline with the manuscript in an *R* markdown document written with the *papaja* package [@Aust2017]]. With `r length(unique(noout$Partno))` participants, the dataset in long format (i.e., each judgment and recall on their own row) included `r length(unique(noout$Partno)) * 63` rows of potential data (i.e., `r length(unique(noout$Partno))` participants $\times$ 63 JORs). `r badjudge` out of range JOR data points (> 100) were corrected to NA. Missing data for JORs or recall were then excluded from the analyses, which included word responses to judgment items (i.e., responding with *cat* instead of a number when prompted to provide a JOR). These items usually excluded a participant from receiving Amazon Mechanical Turk payment, but were included in the datasets found online. In total, `r sum(missingness[c(2,3,4)])` data points were excluded (`r missingness[2]` JOR only, `r missingness[3]` recall only, `r missingness[4]` both), leading to a final *N* of `r missingness[1]` observations. Recall and JOR values were then screened for outliers using Mahalanobis distance at *p* < .001, and no outliers were detected [@Tabachnick2012]. To screen for multicollinearity, we examined correlations between judgment items, DA, and IA. The correlations between judged values, recall, direct and indirect associations were all *r*s < .26. These correlations were similar regardless of judgment condition. 

```{r ANOVAs, include = FALSE}
##judgments
judgment_scores = lme(Judged.Value ~ Judgment, 
    data = noout, 
    random = ~1|Partno, 
    method = "ML",
    na.action = "na.omit")

noout$Judgment2 = factor(noout$Judgment, 
                         levels = c("Semantic", "Associative", "Thematic"))

judgment_scores2 = lme(Judged.Value ~ Judgment2, 
    data = noout, 
    random = ~1|Partno, 
    method = "ML",
    na.action = "na.omit")

##recall
recall_scores = lme(Recall ~ Judgment, 
    data = noout, 
    random = ~1|Partno, 
    method = "ML",
    na.action = "na.omit")

recall_scores2 = lme(Recall ~ Judgment2, 
    data = noout, 
    random = ~1|Partno, 
    method = "ML",
    na.action = "na.omit")
```

The mean JOR for the associative condition (*M* = `r apa(meanJno[1], 2)`, *SD* = `r apa(sdJno[1], 2)`) was lower than the semantic (*M* = `r apa(meanJno[2], 2)`, *SD* = `r apa(sdJno[2], 2)`) and thematic (*M* = `r apa(meanJno[3], 2)`, *SD* = `r apa(sdJno[3], 2)`) conditions. A multilevel model was examined to determine if these JOR values were significantly different using participants as a random factor. Multilevel models were used to retain all data points (rather than averaging over items and conditions) while controlling for correlated error due to participants, which makes these models advantageous for multiway repeated measures designs [@Gelman2006]. Associative judgments were lower than both semantic (*t*(`r summary(judgment_scores)$tTable[2,3]`) = `r apa(summary(judgment_scores)$tTable[2,4],2)`, *p* `r p.value(summary(judgment_scores)$tTable[2,5])`), and thematic judgments (*t*(`r summary(judgment_scores)$tTable[3,3]`) = `r apa(summary(judgment_scores)$tTable[3,4],2)`, *p* `r p.value(summary(judgment_scores)$tTable[3,5])`). Semantic judgments in turn were lower than thematic judgments (*t*(`r summary(judgment_scores2)$tTable[3,3]`) = `r apa(summary(judgment_scores2)$tTable[3,4],2)`, *p* `r p.value(summary(judgment_scores2)$tTable[3,5])`).

Recall averaged around 60% for all three conditions: associative *M* = `r apa(meanRno[1], 2)`, *SD* = `r apa(sdRno[1], 2)`; semantic *M* = `r apa(meanRno[2], 2)`, *SD* = `r apa(sdRno[2], 2)`; thematic *M* = `r apa(meanRno[3], 2)`, *SD* = `r apa(sdRno[3], 2)`. A separate multilevel model indicated that associative recall was lower than semantic recall (*t*(`r summary(recall_scores)$tTable[2,3]`) = `r apa(summary(recall_scores)$tTable[2,4],2)`, *p* `r p.value(summary(recall_scores)$tTable[2,5])`), but not thematic recall (*t*(`r summary(recall_scores)$tTable[3,3]`) = `r apa(summary(recall_scores)$tTable[3,4],2)`, *p* = `r p.value(summary(recall_scores)$tTable[3,5])`). Semantic recall scores were higher than thematic recall scores (*t*(`r summary(recall_scores2)$tTable[3,3]`) = `r apa(summary(recall_scores2)$tTable[3,4],2)`, *p* = `r p.value(summary(recall_scores2)$tTable[3,5])`).

## JAM Slope Bias and Sensitivity

```{r hyp1-work, message = F, warning = F, include = F}
##are average slope and intercept values greater than zero?
##are they within the range of previous work, although maybe controlling for other variables might change them a bit
##frequency of strongest predictor 

##setup
persontable = matrix(NA,
                     nrow=length(names(table(noout$Partno))),
                     ncol=10)
colnames(persontable) = c("Partno", "AIntercept", "ACOS", "AFSG",
                          "SIntercept", "SCOS", "SFSG",
                          "TIntercept", "TCOS", "TFSG")
simnum = 1

for ( person in names(table(noout$Partno)) ){ ##loop over participants
  
  temp1 = subset(noout, Partno == person & Judgment == "Associative")
  temp2 = subset(noout, Partno == person & Judgment == "Semantic")
  temp3 = subset(noout, Partno == person & Judgment == "Thematic")
  
  persontable[ simnum , 1] = person
  
  if (sum(!is.na(temp1$Judged.Value)) > 9) {
    model9 = lm(Judged.Value ~ cosine + swow_fsg, data = temp1)
    persontable[ simnum , 2:4] = model9$coefficients
  }
  
  if(sum(!is.na(temp2$Judged.Value)) > 9) {
    model10 = lm(Judged.Value ~ cosine + swow_fsg, data = temp2)
    persontable[ simnum , 5:7] = model10$coefficients
  }
  
  if(sum(!is.na(temp3$Judged.Value)) > 9) {
    model11 = lm(Judged.Value ~ cosine + swow_fsg, data = temp3)
    persontable[ simnum , 8:10] = model11$coefficients
  }
  
  simnum = simnum + 1
  
}

##set up the output
people = apply(persontable, 2, as.numeric)
people = as.data.frame(people) 

####hyp 1 are these greater than zero####
##single sample t-test for each column, focus on the effect size

hyp1results = apply(people[ , -1], 2, function (x) { d.single.t(m = mean(x, na.rm = T), 
                                u = 0,
                                sd = sd(x, na.rm = T),
                                n = sum(!is.na(x)),
                                a = .05)})
```

```{r hyp1-table1, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
##what happened? make a table
##create a blank table
tableprint = matrix(NA, nrow = 9, ncol = 8)
colnames(tableprint) = c("Variable", "$M$", "$SD$", "$t$", "$df$", "$p$", "$d$", "$95 CI$")

#associative judgment
tableprint[1 , ] = c("Associative Intercept", apa(hyp1results$AIntercept$m, 2, F),
                     apa(hyp1results$AIntercept$sd, 2, F), apa(hyp1results$AIntercept$t, 2, T),
                     hyp1results$AIntercept$df, p.value(hyp1results$AIntercept$p),
                     apa(hyp1results$AIntercept$d, 2, T), paste(apa(hyp1results$AIntercept$dlow, 2, T), 
                                                     "-", apa(hyp1results$AIntercept$dhigh, 2, T)))
tableprint[2 , ] = c("Associative Direct Association", apa(hyp1results$AFSG$m, 2, F),
                     apa(hyp1results$AFSG$sd, 2, F), apa(hyp1results$AFSG$t, 2, T),
                     hyp1results$AFSG$df, p.value(hyp1results$AFSG$p),
                     apa(hyp1results$AFSG$d, 2, T), paste(apa(hyp1results$AFSG$dlow, 2, T), 
                                                     "-", apa(hyp1results$AFSG$dhigh, 2, T)))

tableprint[3 , ] = c("Associative Indirect Association", apa(hyp1results$ACOS$m, 2, F),
                     apa(hyp1results$ACOS$sd, 2, F), apa(hyp1results$ACOS$t, 2, T),
                     hyp1results$ACOS$df, p.value(hyp1results$ACOS$p),
                     apa(hyp1results$ACOS$d, 2, T), paste(apa(hyp1results$ACOS$dlow, 2, T), 
                                                     "-", apa(hyp1results$ACOS$dhigh, 2, T)))

#semantic judgment
tableprint[4 , ] = c("Semantic Intercept", apa(hyp1results$SIntercept$m, 2, F),
                     apa(hyp1results$SIntercept$sd, 2, F), apa(hyp1results$SIntercept$t, 2, T),
                     hyp1results$SIntercept$df, p.value(hyp1results$SIntercept$p),
                     apa(hyp1results$SIntercept$d, 2, T), paste(apa(hyp1results$SIntercept$dlow, 2, T), 
                                                     "-", apa(hyp1results$SIntercept$dhigh, 2, T)))

tableprint[5 , ] = c("Semantic Direct Association", apa(hyp1results$SFSG$m, 2, F),
                     apa(hyp1results$SFSG$sd, 2, F), apa(hyp1results$SFSG$t, 2, T),
                     hyp1results$SFSG$df, p.value(hyp1results$SFSG$p),
                     apa(hyp1results$SFSG$d, 2, T), paste(apa(hyp1results$SFSG$dlow, 2, T), 
                                                     "-", apa(hyp1results$SFSG$dhigh, 2, T)))

tableprint[6 , ] = c("Semantic Indirect Association", apa(hyp1results$SCOS$m, 2, F),
                     apa(hyp1results$SCOS$sd, 2, F), apa(hyp1results$SCOS$t, 2, T),
                     hyp1results$SCOS$df, p.value(hyp1results$SCOS$p),
                     apa(hyp1results$SCOS$d, 2, T), paste(apa(hyp1results$SCOS$dlow, 2, T), 
                                                     "-", apa(hyp1results$SCOS$dhigh, 2, T)))

#thematic judgment
tableprint[7 , ] = c("Thematic Intercept", apa(hyp1results$TIntercept$m, 2, F),
                     apa(hyp1results$TIntercept$sd, 2, F), apa(hyp1results$TIntercept$t, 2, T),
                     hyp1results$TIntercept$df, p.value(hyp1results$TIntercept$p),
                     apa(hyp1results$TIntercept$d, 2, T), paste(apa(hyp1results$TIntercept$dlow, 2, T), 
                                                     "-", apa(hyp1results$TIntercept$dhigh, 2, T)))


tableprint[8 , ] = c("Thematic Direct Association", apa(hyp1results$TFSG$m, 2, F),
                     apa(hyp1results$TFSG$sd, 2, F), apa(hyp1results$TFSG$t, 2, T),
                     hyp1results$TFSG$df, p.value(hyp1results$TFSG$p),
                     apa(hyp1results$TFSG$d, 2, T), paste(apa(hyp1results$TFSG$dlow, 2, T), 
                                                     "-", apa(hyp1results$TFSG$dhigh, 2, T)))

tableprint[9 , ] = c("Thematic Indirect Association", apa(hyp1results$TCOS$m, 2, F),
                     apa(hyp1results$TCOS$sd, 2, F), apa(hyp1results$TCOS$t, 2, T),
                     hyp1results$TCOS$df, p.value(hyp1results$TCOS$p),
                     apa(hyp1results$TCOS$d, 2, T), paste(apa(hyp1results$TCOS$dlow, 2, T), 
                                                     "-", apa(hyp1results$TCOS$dhigh, 2, T)))

apa_table(as.data.frame(tableprint), 
          align = c("l", rep("c", 7)), 
          caption = "Summary Statistics for Hypothesis 1 t-Tests",
          note = "Confidence interval for $d$ was calculated using the non-central $t$-distribution. Hypothesis 1 investigated if bias and sensitivity findings replicated in association and extended to semantic and thematic judgment conditions.",
          col.names = c("Judgment - Variable", "$M$", "$SD$", "$t$", "$df$", "$p$", "$d$", "$95\\% CI$"),
          escape = FALSE
 )

```

First, we sought to replicate bias and sensitivity findings from previous research while expanding the JAM function to include judgments based on three types of memory. DA and IA were used to predict each type of relatedness judgment. JOR values were divided by 100, so as to place them on the same scale as the direct and indirect association measures. Slopes and intercepts were then calculated for each participant's ratings for each of the three JOR conditions, as long as they contained at least nine data points out of the twenty-one that were possible. Single sample *t*-tests were then conducted to test if slope and intercept values significantly differed from zero. See Table \@ref(tab:hyp1-table1) for means and standard deviations. Slopes were then compared to the JAM function, which is characterized by high intercepts (between 40 and 60 on a 100 point scale) and shallow slopes (between 20 and 40). Because of the scaling of our data, to replicate this function, we should expect to find intercepts ranging from .40 to .60 and slopes in the range of .20 to .40. Intercepts for associative, semantic, and thematic JORs were each significant, and all fell within or near the expected range. Overall, thematic JORs had the highest intercept at `r apa(hyp1results$TIntercept$m, 2, F)`, while JORs elicited in the semantic and associative conditions had the lower intercepts at `r apa(hyp1results$SIntercept$m, 2, F)` each. 

The JAM slope was successfully replicated for DA in all three judgment conditions, with slopes falling in the expected range of .20 to .40. For associative judgments, the indirect relation - which is thought to be representative of semantic relatedness - did not predict judgments $M_b$ = `r apa(hyp1results$ACOS$m, 2, F)`. In the thematic judgment condition, the indirect values were positive $M_b$ = `r apa(hyp1results$TCOS$m, 2, F)`, indicating a contribution of both direct $M_b$ = `r apa(hyp1results$TFSG$m, 2, F)` and indirect values to the judgments, which were described as being a mix of both relation types. Last, the semantic judgment condition showed that both direct $M_b$ = `r apa(hyp1results$SFSG$m, 2, F)` and indirect $M_b$ = `r apa(hyp1results$SCOS$m, 2, F)` relations were important (as this judgment type had the highest indirect contribution of the three conditions), indicating that differences in the focus of judgments tap different relations to meet task demands. Overall, JAM slopes were successfully replicated in each JOR condition, and the high intercepts and shallow slopes present across conditions were indicative of overconfidence and insensitivity in participant JORs.

```{r hyp1-part2, include=FALSE}
##group them all by type
##dropping partno column
people_thematic = people[ , 8:10]
people_semantic = people[ , 5:7]
people_associative = people[ , 2:4]

##getting absolute values
people_thematic2 = abs(people_thematic)
people_semantic2 = abs(people_semantic)
people_associative2 = abs(people_associative)

##getting rid of the intercepts
people_thematic3 = people_thematic2[ , -1]
people_semantic3 = people_semantic2[ , -1]
people_associative3 = people_associative2[ , -1]

##finding max coefficents for each row
thematic_output = names(people_thematic3)[max.col(people_thematic3, ties.method="first")]
thematic_output = as.data.frame(thematic_output)

semantic_output = names(people_semantic3)[max.col(people_semantic3, ties.method="first")]
semantic_output = as.data.frame(semantic_output)

associative_output = names(people_associative3)[max.col(people_associative3, ties.method="first")]
associative_output = as.data.frame(associative_output)

##sticking it all together
combined = cbind(people$Partno, associative_output, semantic_output, thematic_output)
colnames(combined) = c("Partno", "Associative", "Semantic", "Thematic")

##rename the things
combined$Associative = factor(combined$Associative,
                           labels = c("COS", "FSG"))
combined$Semantic = factor(combined$Semantic,
                           labels = c("COS", "FSG"))
combined$Thematic = factor(combined$Thematic,
                           labels = c("COS", "FSG"))
summary(combined[ , -1])

##what are the percentages on these?
library(memisc)
p1 = percent(combined$Associative)
p1
p2 = percent(combined$Semantic)
p2
p3 = percent(combined$Thematic)
p3

```

Additionally, we examined the frequency that each predictor variable was the strongest predictor for each of the three JOR conditions. For the associative condition, the direct association was the strongest predictor for `r apa(p1[2],1)`% of the participants. This distinction was less pronounced when examining the semantic and thematic JOR conditions. In the semantic condition, DA was `r apa(p2[2], 1)`% of participants, and in the thematic condition, DA was `r apa(p3[2],1)`% of participants. These results mirror the slope values, such that direct association is strongest when participants are asked to judge associative relations, while a more even split between direct and indirect predictors was found when participants were asked to consider semantic and thematic relations. 

## Interaction between Relation when Predicting Judgments of Relatedness

```{r hyp2-table, echo=FALSE, results='asis'}

#center the vars
noout$zfsg = scale(noout$swow_fsg, scale = F)
noout$zcosine = scale(noout$cosine, scale = F)

overallh2 = lme(Judged.Value ~ Judgment + 
               zfsg*zcosine, 
             data = noout, 
             method = "ML", 
             na.action = "na.omit",
             random = ~1|Partno)

#summary(overallh2)

#split on cosine because that's what we did before
noout$low_cosine = noout$zcosine + sd(noout$zcosine)
noout$high_cosine = noout$zcosine - sd(noout$zcosine)

overallh2_low = lme(Judged.Value ~ Judgment + 
               zfsg*low_cosine, 
             data = noout, 
             method = "ML", 
             na.action = "na.omit",
             random = ~1|Partno)

overallh2_high = lme(Judged.Value ~ Judgment + 
               zfsg*high_cosine, 
             data = noout, 
             method = "ML", 
             na.action = "na.omit",
             random = ~1|Partno)

#summary(overallh2_low) ##.38

#summary(overallh2) ##.30

#summary(overallh2_high) ##.22 

tableprint = matrix(NA, nrow = 8, ncol = 5)

tableprint[ , 1] = c("Intercept", "Semantic Judgment", "Thematic Judgment", 
                     "Z Direct Association", "Z Indirect Association", "Z Interaction", "Z Direct Association Low", "Z Direct Association High")
tableprint[1:6 , 2:5] = summary(overallh2)$tTable[ , c(1,2,4,5)]

tableprint[7, 2:5] = summary(overallh2_low)$tTable[4, c(1,2,4,5)]
tableprint[8, 2:5] = summary(overallh2_high)$tTable[4, c(1,2,4,5)]

tableprint[ , c(2,3,4)] = printnum(as.numeric(tableprint[ , c(2,3,4)]))
tableprint[ , 5] = printp(as.numeric(tableprint[ , 5]))

colnames(tableprint) = c("Statistic", "Coefficient", "$SE$", "$t$", "$p$")

apa_table(as.data.frame(tableprint),
          align = c("l", rep("c", 4)), 
          caption = "MLM Statistics for Hypothesis 2",
          note = "Direct and indirect association were mean centered. The table shows results from the second hypothesis wherein an interaction between direct and indirect association was investigated predicting judgment score. $df$ = 19404",
          escape = FALSE
)

```

```{r hyp2-breakdown, include = F}

overallh2.a = lme(Judged.Value ~ zfsg*zcosine, 
             data = noout[noout$Judgment2 == "Associative", ],
             method = "ML", 
             na.action = "na.omit",
             random = ~1|Partno)
summary(overallh2.a)

overallh2.alow = lme(Judged.Value ~ zfsg*low_cosine, 
             data = noout[noout$Judgment2 == "Associative", ],
             method = "ML", 
             na.action = "na.omit",
             random = ~1|Partno)
summary(overallh2.alow)

overallh2.ahigh = lme(Judged.Value ~ zfsg*high_cosine, 
             data = noout[noout$Judgment2 == "Associative", ],
             method = "ML", 
             na.action = "na.omit",
             random = ~1|Partno)
summary(overallh2.ahigh)

overallh2.s= lme(Judged.Value ~ zfsg*zcosine, 
             data = noout[noout$Judgment2 == "Semantic", ],
             method = "ML", 
             na.action = "na.omit",
             random = ~1|Partno)
summary(overallh2.s)

overallh2.slow = lme(Judged.Value ~ zfsg*low_cosine, 
             data = noout[noout$Judgment2 == "Semantic", ],
             method = "ML", 
             na.action = "na.omit",
             random = ~1|Partno)
summary(overallh2.slow)

overallh2.shigh = lme(Judged.Value ~ zfsg*high_cosine, 
             data = noout[noout$Judgment2 == "Semantic", ],
             method = "ML", 
             na.action = "na.omit",
             random = ~1|Partno)
summary(overallh2.shigh)

overallh2.t = lme(Judged.Value ~ zfsg*zcosine, 
             data = noout[noout$Judgment2 == "Thematic", ],
             method = "ML", 
             na.action = "na.omit",
             random = ~1|Partno)
summary(overallh2.t)

overallh2.tlow = lme(Judged.Value ~ zfsg*low_cosine, 
             data = noout[noout$Judgment2 == "Thematic", ],
             method = "ML", 
             na.action = "na.omit",
             random = ~1|Partno)
summary(overallh2.tlow)

overallh2.thigh = lme(Judged.Value ~ zfsg*high_cosine, 
             data = noout[noout$Judgment2 == "Thematic", ],
             method = "ML", 
             na.action = "na.omit",
             random = ~1|Partno)
summary(overallh2.thigh)

tableprint = matrix(NA, nrow = 18, ncol = 7)

tableprint[ , 1] = c(rep("Associative", 6), rep("Semantic", 6), rep("Thematic", 6))
tableprint[ , 2] = c("Intercept", "Z Direct Association", "Z Indirect Association", "Z Interaction", "Z Direct Association Low", "Z Direct Association High",
                     "Intercept", "Z Direct Association", "Z Indirect Association", "Z Interaction", "Z Direct Association Low", "Z Direct Association High",
                     "Intercept", "Z Direct Association", "Z Indirect Association", "Z Interaction", "Z Direct Association Low", "Z Direct Association High")

colnames(tableprint) = c("Judgment Condition", "Statistic", "Coefficient", "SE", "df","t", "p")

tableprint[1:4, 3:7] = summary(overallh2.a)$tTable
tableprint[5, 3:7] = summary(overallh2.alow)$tTable[2, ]
tableprint[6, 3:7] = summary(overallh2.ahigh)$tTable[2, ]

tableprint[7:10, 3:7] = summary(overallh2.s)$tTable
tableprint[11, 3:7] = summary(overallh2.slow)$tTable[2, ]
tableprint[12, 3:7] = summary(overallh2.shigh)$tTable[2, ]

tableprint[13:16, 3:7] = summary(overallh2.t)$tTable
tableprint[17, 3:7] = summary(overallh2.tlow)$tTable[2, ]
tableprint[18, 3:7] = summary(overallh2.thigh)$tTable[2, ]

write.csv(tableprint, "hyp2_by_condition.csv", row.names = F)
```

```{r hyp2graph, echo=FALSE, fig.cap = "Simple slopes graph displaying the slope of direct association when predicting JORs at low, average, and high indirect association. All variables were mean centered. The top left panel displays overall analysis adjusting for condition. The other three panels indicate associative (no interaction), semantic, and thematic judgments individually.", fig.height=6, fig.width=8}

plot1 = ggplot(noout, aes(x = swow_fsg, y = Judged.Value)) +
  labs(x = "Direct Association", y = "Judgments") +
  scale_size_continuous(guide = FALSE) +
  geom_abline(aes(intercept = summary(overallh2_low)$tTable[1,1], slope = summary(overallh2_low)$tTable[4,1], linetype = "-1SD Z-IA")) +
  geom_abline(aes(intercept = summary(overallh2)$tTable[1,1], slope = summary(overallh2)$tTable[4,1], linetype = "Average Z-IA")) +
  geom_abline(aes(intercept = summary(overallh2_high)$tTable[1,1], slope = summary(overallh2_high)$tTable[4,1], linetype = "+1SD Z-IA")) +
  scale_linetype_manual(values = c("dotted", "dashed", "solid"),
                        breaks = c("-1SD Z-IA", "Average Z-IA", "+1SD Z-IA"),
                        name = "Simple Slope") +
  coord_cartesian(xlim = c(0, 1), ylim = c(.1, 1)) +
  geom_vline(xintercept = -.10) +
  geom_hline(yintercept = 0) +
  cleanup2 +
  labs(title = "Overall Results") + 
  NULL

plot1.a = ggplot(noout[noout$Judgment2 == "Associative", ], aes(x = swow_fsg, y = Judged.Value)) +
  labs(x = "Direct Association", y = "Judgments") +
  scale_size_continuous(guide = FALSE) +
  geom_abline(aes(intercept = summary(overallh2.alow)$tTable[1,1], slope = summary(overallh2.alow)$tTable[2,1], linetype = "-1SD Z-IA")) +
  geom_abline(aes(intercept = summary(overallh2.a)$tTable[1,1], slope = summary(overallh2.a)$tTable[2,1], linetype = "Average Z-IA")) +
  geom_abline(aes(intercept = summary(overallh2.ahigh)$tTable[1,1], slope = summary(overallh2.ahigh)$tTable[2,1], linetype = "+1SD Z-IA")) +
  scale_linetype_manual(values = c("dotted", "dashed", "solid"),
                        breaks = c("-1SD Z-IA", "Average Z-IA", "+1SD Z-IA"),
                        name = "Simple Slope") +
  coord_cartesian(xlim = c(0, 1), ylim = c(.1, 1)) +
  geom_vline(xintercept = -.10) +
  geom_hline(yintercept = 0) +
  cleanup2 +
  labs(title = "Associative Judgments") + 
  NULL

plot1.s = ggplot(noout[noout$Judgment2 == "Semantic", ], aes(x = swow_fsg, y = Judged.Value)) +
  labs(x = "Direct Association", y = "Judgments") +
  scale_size_continuous(guide = FALSE) +
  geom_abline(aes(intercept = summary(overallh2.slow)$tTable[1,1], slope = summary(overallh2.slow)$tTable[2,1], linetype = "-1SD Z-IA")) +
  geom_abline(aes(intercept = summary(overallh2.s)$tTable[1,1], slope = summary(overallh2.s)$tTable[2,1], linetype = "Average Z-IA")) +
  geom_abline(aes(intercept = summary(overallh2.shigh)$tTable[1,1], slope = summary(overallh2.shigh)$tTable[2,1], linetype = "+1SD Z-IA")) +
  scale_linetype_manual(values = c("dotted", "dashed", "solid"),
                        breaks = c("-1SD Z-IA", "Average Z-IA", "+1SD Z-IA"),
                        name = "Simple Slope") +
  coord_cartesian(xlim = c(0, 1), ylim = c(.1, 1)) +
  geom_vline(xintercept = -.10) +
  geom_hline(yintercept = 0) +
  cleanup2 +
  labs(title = "Semantic Judgments") + 
  NULL

plot1.t = ggplot(noout[noout$Judgment2 == "Thematic", ], aes(x = swow_fsg, y = Judged.Value)) +
  labs(x = "Direct Association", y = "Judgments") +
  scale_size_continuous(guide = FALSE) +
  geom_abline(aes(intercept = summary(overallh2.tlow)$tTable[1,1], slope = summary(overallh2.tlow)$tTable[2,1], linetype = "-1SD Z-IA")) +
  geom_abline(aes(intercept = summary(overallh2.t)$tTable[1,1], slope = summary(overallh2.t)$tTable[2,1], linetype = "Average Z-IA")) +
  geom_abline(aes(intercept = summary(overallh2.thigh)$tTable[1,1], slope = summary(overallh2.thigh)$tTable[2,1], linetype = "+1SD Z-IA")) +
  scale_linetype_manual(values = c("dotted", "dashed", "solid"),
                        breaks = c("-1SD Z-IA", "Average Z-IA", "+1SD Z-IA"),
                        name = "Simple Slope") +
  coord_cartesian(xlim = c(0, 1), ylim = c(.1, 1)) +
  geom_vline(xintercept = -.10) +
  geom_hline(yintercept = 0) +
  cleanup2 +
  labs(title = "Thematic Judgments") + 
  NULL

# arrange plots together
legend = get_legend(plot1)
hyp2graphout <- plot_grid(plot1 + theme(legend.position="none"),
                   plot1.a + theme(legend.position="none"),
                   plot1.s + theme(legend.position="none"),
                   plot1.t + theme(legend.position = c(.75, .35)),
                   hjust = -1,
                   nrow = 2)
hyp2graphout
```

Next, we sought to test the interactive relationship between associative and semantic overlap. If this interactive relationship exists, a statistical interaction should be detected between the database norms when predicting performance on the judgment task. As such, the goal of next analysis was to test for this interaction between direct and indirect association when predicting participant JORs. First, the database norms were mean centered to aid in interpretation. The *nlme* package and *lme* function were used to calculate these analyses [@Pinheiro2017]. A maximum likelihood multilevel model was used to test for the interaction between DA and IA when predicting JOR values, with participant number used as the random intercept factor. The type of JOR being elicited was controlled for so as to better assess the impact of each word overlap measure regardless of JOR condition. This analysis resulted in a significant interaction between DA and IA ($\beta$ = `r tableprint[6, 2]`, *p* `r tableprint[6, 5]`), which is examined below in a simple slopes analysis. Table \@ref(tab:hyp2-table) includes values for main effects, two-way interaction, and the simple slopes.

To investigate this interaction, simple slopes were calculated for low, average, and high levels of indirect association. This variable was chosen to show the effects of direct associations across levels of indirect association. At low levels of indirect relation (and thus low levels of the semantic network) we found the largest $\beta$ for direct association, `r tableprint[7,2]`. As indirect relation increased, we found decreasing predictiveness of direct relation, average direct $\beta$ = `r tableprint[4,2]`, and high direct $\beta$ = `r tableprint[8,2]`. Figure \@ref(fig:hyp2graph) displays the two-way interaction with this seesaw type effect, indicating that higher semantic network relation results in lower usefulness of direct associative relation. Further, we then split the data by judgment type to visualize the interaction in each condition, as Hypothesis 1 indicated some task demand characteristics. The results are consistent in semantic and thematic judgments (lower two panels), while no interaction was found in the associative judgment condition (top right panel). The complete table of predictors for these analyses can be found at http://osf.io/y8h7v.

## Interaction between Relation when Predicting Recall

```{r hyp3-table, echo=FALSE, results='asis'}

recalloverall = glmer(Recall ~ (1|Partno) + Judgment + 
                        Judged.Value + zfsg*zcosine,
                      data = noout,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)
#summary(recalloverall) ##1.63

recalloverall_low = glmer(Recall ~ (1|Partno) + Judgment + 
                        Judged.Value + zfsg*low_cosine,
                      data = noout,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

#summary(recalloverall_low) #1.89

recalloverall_high = glmer(Recall ~ (1|Partno) + Judgment + 
                        Judged.Value + zfsg*high_cosine,
                      data = noout,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

#summary(recalloverall_high) #1.37

tableprint = matrix(NA, nrow = 9, ncol = 5)

tableprint[ , 1] = c("Intercept", "Semantic Judgment", "Thematic Judgment", "Judged Value",
                     "Z Direct Association", "Z Indirect Association", "Z Interaction", "Z Direct Association Low", "Z Direct Association High")
tableprint[1:7 , 2:5] = coef(summary(recalloverall))[ , ]

tableprint[8, 2:5] = coef(summary(recalloverall_low))[5 , ]
tableprint[9, 2:5] = coef(summary(recalloverall_high))[5 , ]

tableprint[ , c(2,3,4)] = printnum(as.numeric(tableprint[ , c(2,3,4)]))
tableprint[ , 5] = printp(as.numeric(tableprint[ , 5]))

colnames(tableprint) = c("Statistic", "Coefficient", "$SE$","$Z$", "$p$")


apa_table(as.data.frame(tableprint),
          align = c("l", rep("c", 4)), 
          caption = "MLM Statistics for Hypothesis 3",
          note = "Direct and indirect association were mean centered. The table shows results from the third hypothesis extending the interaction between direct and indirect associations to recall for words.",
          escape = FALSE
)

```

```{r hyp3-breakdown, include = F}

recalloverall.a = glmer(Recall ~ (1|Partno) + Judged.Value + zfsg*zcosine,
                      data = noout[noout$Judgment == "Associative", ],
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

recalloverall_low.a = glmer(Recall ~ (1|Partno) + Judged.Value + zfsg*low_cosine,
                      data = noout[noout$Judgment == "Associative", ],
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

recalloverall_high.a = glmer(Recall ~ (1|Partno) + Judged.Value + zfsg*high_cosine,
                      data = noout[noout$Judgment == "Associative", ],
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

recalloverall.s = glmer(Recall ~ (1|Partno) + Judged.Value + zfsg*zcosine,
                      data = noout[noout$Judgment == "Semantic", ],
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

recalloverall_low.s = glmer(Recall ~ (1|Partno) + Judged.Value + zfsg*low_cosine,
                      data = noout[noout$Judgment == "Semantic", ],
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

recalloverall_high.s = glmer(Recall ~ (1|Partno) + Judged.Value + zfsg*high_cosine,
                      data = noout[noout$Judgment == "Semantic", ],
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

recalloverall.t = glmer(Recall ~ (1|Partno) + Judged.Value + zfsg*zcosine,
                      data = noout[noout$Judgment == "Thematic", ],
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

recalloverall_low.t = glmer(Recall ~ (1|Partno) + Judged.Value + zfsg*low_cosine,
                      data = noout[noout$Judgment == "Thematic", ],
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

recalloverall_high.t = glmer(Recall ~ (1|Partno) + Judged.Value + zfsg*high_cosine,
                      data = noout[noout$Judgment == "Thematic", ],
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

tableprint = matrix(NA, nrow = 21, ncol = 6)

tableprint[ , 1] = c(rep("Associative", 7), rep("Semantic", 7), rep("Thematic", 7))
tableprint[ , 2] = c("Intercept","Judged Value", "Z Direct Association", "Z Indirect Association", "Z Interaction", "Z Direct Association Low", "Z Direct Association High",
                     "Intercept","Judged Value", "Z Direct Association", "Z Indirect Association", "Z Interaction", "Z Direct Association Low", "Z Direct Association High",
                     "Intercept", "Judged Value", "Z Direct Association", "Z Indirect Association", "Z Interaction", "Z Direct Association Low", "Z Direct Association High")

colnames(tableprint) = c("Judgment Condition", "Statistic", "Coefficient", "SE", "t", "p")

tableprint[1:5 , 3:6] = coef(summary(recalloverall.a))[ , ]
tableprint[6, 3:6] = coef(summary(recalloverall_low.a))[3 , ]
tableprint[7, 3:6] = coef(summary(recalloverall_high.a))[3, ]
tableprint[8:12 , 3:6] = coef(summary(recalloverall.s))[ , ]
tableprint[13, 3:6] = coef(summary(recalloverall_low.s))[3 , ]
tableprint[14, 3:6] = coef(summary(recalloverall_high.s))[3, ]
tableprint[15:19 , 3:6] = coef(summary(recalloverall.t))[ , ]
tableprint[20, 3:6] = coef(summary(recalloverall_low.t))[3 , ]
tableprint[21, 3:6] = coef(summary(recalloverall_high.t))[3, ]

write.csv(tableprint, "hyp3_by_condition.csv", row.names = F)
```

```{r hyp3graph, echo=FALSE, fig.cap = "Simple slopes graph displaying the slope of direct association when predicting recall at low, average, and high indirect association. All variables were mean centered. The top left panel displays overall analysis adjusting for condition. The other three panels indicate associative (no interaction), semantic, and thematic judgments individually.", fig.height=6, fig.width=8}

plot1 = ggplot(noout, aes(x = swow_fsg, y = Recall)) +
  labs(x = "Direct Association", y = "Recall") +
  scale_size_continuous(guide = FALSE) +
  geom_abline(aes(intercept = coef(summary(recalloverall_low))[1,1], slope = coef(summary(recalloverall_low))[5,1], linetype = "-1SD Z-IA")) +
  geom_abline(aes(intercept = coef(summary(recalloverall))[1,1], slope = coef(summary(recalloverall))[5,1], linetype = "Average Z-IA")) +
  geom_abline(aes(intercept = coef(summary(recalloverall_high))[1,1], slope = coef(summary(recalloverall_high))[5,1], linetype = "+1SD Z-IA")) +
  scale_linetype_manual(values = c("dotted", "dashed", "solid"),
                        breaks = c("-1SD Z-IA", "Average Z-IA", "+1SD Z-IA"),
                        name = "Simple Slope") +
  coord_cartesian(xlim = c(0, 1), ylim = c(.1, 1)) +
  geom_vline(xintercept = -.10) +
  geom_hline(yintercept = 0) +
  cleanup2 +
  labs(title = "Overall Judgments") + 
  NULL

plot1.a = ggplot(noout[noout$Judgment == "Associative", ], aes(x = swow_fsg, y = Recall)) +
  labs(x = "Direct Association", y = "Recall") +
  scale_size_continuous(guide = FALSE) +
  geom_abline(aes(intercept = coef(summary(recalloverall_low.a))[1,1], slope = coef(summary(recalloverall_low.a))[3,1], linetype = "-1SD Z-IA")) +
  geom_abline(aes(intercept = coef(summary(recalloverall.a))[1,1], slope = coef(summary(recalloverall.a))[3,1], linetype = "Average Z-IA")) +
  geom_abline(aes(intercept = coef(summary(recalloverall_high.a))[1,1], slope = coef(summary(recalloverall_high.a))[3,1], linetype = "+1SD Z-IA")) +
  scale_linetype_manual(values = c("dotted", "dashed", "solid"),
                        breaks = c("-1SD Z-IA", "Average Z-IA", "+1SD Z-IA"),
                        name = "Simple Slope") +
  coord_cartesian(xlim = c(0, 1), ylim = c(.1, 1)) +
  geom_vline(xintercept = -.10) +
  geom_hline(yintercept = 0) +
  cleanup2 +
  labs(title = "Associative Judgments") + 
  NULL

plot1.s = ggplot(noout[noout$Judgment == "Semantic", ], aes(x = swow_fsg, y = Recall)) +
  labs(x = "Direct Association", y = "Recall") +
  scale_size_continuous(guide = FALSE) +
  geom_abline(aes(intercept = coef(summary(recalloverall_low.s))[1,1], slope = coef(summary(recalloverall_low.s))[3,1], linetype = "-1SD Z-IA")) +
  geom_abline(aes(intercept = coef(summary(recalloverall.s))[1,1], slope = coef(summary(recalloverall.s))[3,1], linetype = "Average Z-IA")) +
  geom_abline(aes(intercept = coef(summary(recalloverall_high.s))[1,1], slope = coef(summary(recalloverall_high.s))[3,1], linetype = "+1SD Z-IA")) +
  scale_linetype_manual(values = c("dotted", "dashed", "solid"),
                        breaks = c("-1SD Z-IA", "Average Z-IA", "+1SD Z-IA"),
                        name = "Simple Slope") +
  coord_cartesian(xlim = c(0, 1), ylim = c(.1, 1)) +
  geom_vline(xintercept = -.10) +
  geom_hline(yintercept = 0) +
  cleanup2 +
  labs(title = "Semantic Judgments") + 
  NULL

plot1.t = ggplot(noout[noout$Judgment == "Thematic", ], aes(x = swow_fsg, y = Recall)) +
  labs(x = "Direct Association", y = "Recall") +
  scale_size_continuous(guide = FALSE) +
  geom_abline(aes(intercept = coef(summary(recalloverall_low.t))[1,1], slope = coef(summary(recalloverall_low.t))[3,1], linetype = "-1SD Z-IA")) +
  geom_abline(aes(intercept = coef(summary(recalloverall.t))[1,1], slope = coef(summary(recalloverall.t))[3,1], linetype = "Average Z-IA")) +
  geom_abline(aes(intercept = coef(summary(recalloverall_high.t))[1,1], slope = coef(summary(recalloverall_high.t))[3,1], linetype = "+1SD Z-IA")) +
  scale_linetype_manual(values = c("dotted", "dashed", "solid"),
                        breaks = c("-1SD Z-IA", "Average Z-IA", "+1SD Z-IA"),
                        name = "Simple Slope") +
  coord_cartesian(xlim = c(0, 1), ylim = c(.1, 1)) +
  geom_vline(xintercept = -.10) +
  geom_hline(yintercept = 0) +
  cleanup2  +
  labs(title = "Thematic Judgments") + 
  NULL

# arrange plots together
legend = get_legend(plot1)
hyp3graphout <- plot_grid(plot1 + theme(legend.position="none"),
                   plot1.a + theme(legend.position="none"),
                   plot1.s + theme(legend.position="none"),
                   plot1.t + theme(legend.position = c(.75, .35)),
                   hjust = -1,
                   nrow = 2)
hyp3graphout
```

Given the results of Hypothesis 2, we then sought to extend the analysis to participant recall scores. A multilevel logistic regression was used with the *lme4* package and *glmer()* function [@Bates2015], testing the interaction between DA and IA when predicting participant recall. As with the previous hypothesis, we controlled for JOR condition and, additionally, covaried JOR ratings. Participants were used as a random intercept factor. Judged values were not a significant predictor of recall, ($\beta$ = `r tableprint[4, 2]`, *p* = `r tableprint[4, 5]`). A significant interaction was detected between direct and indirect relations ($\beta$ = `r tableprint[7, 2]`, *p* = `r tableprint[7, 5]`). See Table \@ref(tab:hyp3-table) for main effects, interaction, and simple slopes. 

The same moderation process used in Hypothesis 2 was then repeated, with simple slopes calculated at low, average, and high levels of indirect association. The same pattern of results emerged where low levels of indirect association resulted in the largest contribution of direct association $\beta$ = `r tableprint[8, 2]`. As indirect association increased, direct association coefficients decreased, average direct $\beta$ = `r tableprint[5,2]`, and high direct $\beta$ = `r tableprint[9,2]`. Thus, the cognitive processes of recall and judgment appear to operate similarly on the memory network. Again, we analyzed these results separately for each condition, as shown in Figure \@ref(fig:hyp3graph). The results indicated that there was not an interaction for associative judgments, but semantic and thematic judgments included the direct-indirect association interaction as described above. These results mirror those found in for judgments, and the entire set of predictors can be found online. 

## Predicting Recall with JAM Slopes

```{r hyp4-table, echo=FALSE, results='asis'}

##merge recall back with slopes from the people dataset
hyp4data = merge(people, noout, by = "Partno")

##association
assoch4 = glmer(Recall ~ (1|Partno) + ACOS + AFSG + AIntercept,
                data = hyp4data,
                family = binomial,
                control = glmerControl(optimizer = "bobyqa"),
                nAGQ = 1)

##semantics
semh4 = glmer(Recall ~ (1|Partno) + SCOS + SFSG + SIntercept,
                data = hyp4data,
                family = binomial,
                control = glmerControl(optimizer = "bobyqa"),
                nAGQ = 1)

##thematics
themeh4 = glmer(Recall ~ (1|Partno) + TCOS + TFSG + TIntercept,
                data = hyp4data,
                family = binomial,
                control = glmerControl(optimizer = "bobyqa"),
                nAGQ = 1)

##create a blank table
tableprint = matrix(NA, nrow = 12, ncol = 5)
colnames(tableprint) = c("Judgment - Variable", "$b$", "$SE$", "$z$", "$p$")

tableprint[1:4, 2:5] = coef(summary(assoch4))
tableprint[1:4, 1] = c("(Intercept)", "Associative Indirect Association", "Associative Direct Association", "Associative Intercept")

tableprint[5:8, 2:5] = coef(summary(semh4))
tableprint[5:8, 1] = c("(Intercept)", "Semantic Indirect Association", "Semantic Direct Association", "Semantic Intercept")

tableprint[9:12, 2:5] = coef(summary(themeh4))
tableprint[9:12, 1] = c("(Intercept)", "Thematic  Indirect Association", "Thematic Direct Association", "Thematic Intercept")

tableprint[ , 2] = apa(as.numeric(tableprint[ , 2]),3,T) 
tableprint[ , 3] = apa(as.numeric(tableprint[ , 3]),3,T)
tableprint[ , 4] = apa(as.numeric(tableprint[ , 4]),3,T)
tableprint[ , 5] = apply(as.data.frame(as.numeric(tableprint[ , 5])), 1, p.value)

apa_table(as.data.frame(tableprint[c(1,3,2,4,5,7,6,8,9,11,10,12) , ]),
          align = c("l", rep("c", 4)), 
          caption = "MLM Statistics for Hypothesis 4",
          note = "This hypothesis investigated how each judgment's original bias intercept score and sensitivity slope score would predict the corresponding judgment condition. (Intercept) is the intercept for the overall model, while the Judgment Intercepts are the bias scores for each participant from Hypothesis 1.",
          escape = FALSE
)
```

In our fourth and final hypothesis, we investigated whether the JOR slopes and intercepts obtained in Hypothesis 1 would be predictive of recall ability. Whereas Hypothesis 3 indicated that word relatedness was directly related to recall performance, this hypothesis instead looked at whether or not participants' sensitivity and bias to word relatedness could be used as a predictor of recall [@Maki2007]. This analysis was conducted with a multilevel logistic regression, as described in Hypothesis 3, where each direct and indirect slope and intercept was used as a predictor of recall using participant number as a random intercept factor. These analyses were separated by judgment condition, so that each set of JOR slopes and intercepts was used to predict recall. The separation controlled for the number of variables in the equation, as all slopes and intercepts would have resulted in overfitting. These values were obtained from Hypothesis 1, where each participant's individual slopes and intercepts were calculated for associative, semantic, and thematic JOR conditions. Table \@ref(tab:hyp1-table1) shows average slopes and intercepts for recall for each of the three types of memory, and Table \@ref(tab:hyp4-table) portrays the regression coefficients and statistics. 

In the associative condition, the direct association slope significantly predicted recall (*b* = `r printnum(as.numeric(tableprint[3, 2]), digits = 2)`, *p* = `r tableprint[3, 5]`), while the indirect association did not predict recall (*b* = `r printnum(as.numeric(tableprint[2, 2]), digits = 2)`, *p* = `r tableprint[2, 5]`). However, in both of the semantic and thematic conditions, the direct and indirect relations are both predictors, along with the intercepts (see Table \@ref(tab:hyp4-table)). In each of these judgment conditions, the direct and indirect association predictors have similar coefficients, showing equal weight in the prediction of recall. Therefore, higher levels of sensitivity in judgments contribute to higher recall, and higher bias in judgments also leads to more recall. These results mimic the results from across our hypotheses, wherein the associative condition was predicted by direct associations, while the semantic and thematic conditions were predicted by both direct and indirect associations. This analysis indicated the extent to which the cognitive processes are related to each other as part of the memory network (i.e., judgment sensitivity predicting recall), furthering the previous two analyses, which illustrated the nature of those cognitive processes' relationship with the underlying memory network. 

# Discussion

```{r testnodirect, include = F}
nodirect = subset(noout, swow_fsg == 0)
length(unique(nodirect$pair))
tapply(nodirect$Judged.Value, nodirect$Judgment, mean, na.rm = T)
tapply(nodirect$Judged.Value, nodirect$Judgment, sd, na.rm = T)
```

This study investigated the relationship between direct (associative) and indirect (semantic) relations and their effect on participant JORs and recall performance through the testing of four hypotheses. In our first hypothesis, we show that bias and sensitivity findings first proposed by @Maki2007a successfully replicated in all three judgment conditions. Participants displayed high intercepts and shallow slopes, suggesting overconfidence in judgment making and an insensitivity to changes in strength between pairs. Additionally, when looking at the frequency that each predictor was the strongest in making JORs, direct association was the strongest predictor for the associative condition, with a nearly even split between direct and indirect association for the semantic and thematic conditions. The observation that direct association was the strongest predictor of both judgments and recall within the associative condition and that the indirect association was strongest for the semantic and thematic conditions is not surprising. Direct associations are designed to capture the associative overlap shared between word pairs whereas indirect associations are thought to tap into elements of the overall semantic network and represent similarities in meaning rather than cue-target probabilities. Therefore, these results appear to reflect the task demands for each judgment condition. This finding may also be comparable to results in the semantic priming literature, wherein direct and indirectly related pairs show different priming effects [@Lerner2012], often modulated by task [@Jones2010; @Jones2012a], and recognition has also been shown to be influenced by indirect relations [@Huff2011; @Huff2012b].

Finally, in contrast to the study conducted by @DeDeyne2013a, we found bias in judgments for pairs with no direct relation across each of the three judgment conditions (average judgment = `r printnum(mean(nodirect$Judged.Value, na.rm = T)*100)`); however, these findings should be viewed cautiously as our stimuli contained only `r length(unique(nodirect$pair))` item pairs that had no direct association. The SWOW norms size and construction lessens the measurement bias in the data, and these results support that some overestimation bias likely exists beyond potential measurement bias, especially in line with the traditional judgments of learning literature. 

Our second hypothesis examined if there was an interaction between direct and indirect association when predicting participant JORs. The interaction was present as a seesaw effect wherein increasing levels of indirect association lead to decreasing predictiveness of direct association. Therefore, as semantic connections become stronger in the memory network, the direct associative connections become less useful for judgments. This finding was extended to recall in our third hypothesis, supporting the notion that recall and judgment cognitive processes draw in similar ways on the memory network. 

Finally, our fourth hypothesis used the JOR slopes and intercepts calculated in Hypothesis 1 to investigate whether participants' bias and sensitivity to word relatedness could be used to predict recall. For the associative condition, the only the direct association slope significantly predicted recall. In the semantic and thematic conditions, both direct and indirect associations, along with their intercepts, predicted recall. These results mirror results from Hypothesis 1 suggesting that task demands from the judgment instructions carry over into recall processes. For direct association, increasing sensitivity to the relation between pairs lead to increasing likelihood of memory, which is not surprising. Indirect association also showed this effect, that stronger indirect sensitivity to word pair relation also increased memory in the thematic and semantic judgment conditions, similar to indirect memory results from @Huff2011 and @Huff2012b. The intercepts or bias estimates from the first hypothesis indicated that increasing participant overestimation of weakly related pairs also predicted increased recall. Potentially, this result can be viewed as self-fulfilling, the more related participants thought the weakly related word pairs were, they more likely they were to remember them. 

Overall, our findings indicated the degree to which the processing of direct and indirect word-pair network information impacts retrieval and judgment making tasks. Previous research has shown the effects of direct associations on priming [@Buchanan2010; @Hutchison2003], cued-recall [@Nelson1997; @Nelson2001], judgments of associative memory [@Maki2007; @Maki2007a; @Valentine2013; @DeDeyne2013a] and response latencies [@DeDeyne2013] to name a few. Our results suggest a competitive network based on task-demand. When instructed to focus on associative relatedness, direct association strength was a strong (and often the only) predictor of judgment or recall. When directed to focus on semantic or thematic type relations, both indirect and direct association play a role in judgments and recall. Further, this effect was interactive, wherein different levels of indirect semantic strength lead to different activation of the direct associative network. As indirect strength increases, the effect of direct strength decreases, albeit does not completely diminish.

Finally, future studies may wish to consider the effect of each concept's linguistic features (frequency, orthography, part of speech, etc.), as these properties have been shown to influence judgments and recall. The type, or ontology [@Wu2009], of the relation may provide clues as to judgments and recall. @DeDeyne2016 illustrated how a spreading activation model with random walks can account for participant's understanding of similarity, even when word-pair relation would be considered very weak. These models provide future avenues for application to judgment and recall processes, as we have shown they are related to the same direct and indirect network of association.

## Compliance with Ethical Standards

The authors declare that they have no conflict of interest. The study was approved by the Institutional Review Board at Missouri State University. Participants filled out an informed consent at the beginning of the study, after accepting the HIT on Mechanical Turk. The complete study with consent form can be found on our OSF page: http://osf.io/y8h7v.




\newpage

# References

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
